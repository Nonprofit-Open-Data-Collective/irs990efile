#' Split Index into Groups
#'
#' Divides a vector of URLs into smaller groups of a specified size.
#'
#' @param index A data frame containing a column `URL` with URLs to be split.
#' @param group.size An integer specifying the maximum size of each group.
#'
#' @return A list of URL groups.
#' @examples
#' groups <- split_index(index, group.size = 1000)
#' @export
split_index <- function(index, group.size = 1000) {
  urls <- index$URL
  f <- ((1:length(urls)) + group.size - 1) %/% group.size
  f <- paste0("g", f)
  f <- factor(f, levels = unique(f))
  url.list <- split(urls, f)
  return(url.list)
}

#' Parse NPO Data
#'
#' Parses XML data from a given URL and applies specified processing functions.
#'
#' @param url A string containing the URL of the XML file.
#' @param fx.names A list of functions to apply to the XML document.
#'
#' @return A named list with parsed data or a failure indicator if the URL is inaccessible.
#' @examples
#' npo_data <- parse_npo(url, fx.names)
#' @export
parse_npo <- function(url, fx.names, logXP=TRUE ) {
  doc <- NULL
  try(doc <- xml2::read_xml(url), silent = TRUE)
  if (is.null(doc)) {
    one.npo <- list()
    one.npo[["FAIL"]] <- url
    log_fails( url )
    return(one.npo)
  }
  xml2::xml_ns_strip(doc)
  TABLE.HEADERS <- get_table_headers() # creates env var through superassignment
  fx.names <- c( fx.names, "BUILD_SCHEDULE_TABLE" )  # bst not in cc
  one.npo <- sapply(fx.names, do.call, list(doc, url))
  if( logXP ){ log_missing_xpaths( doc, url ) }
  return(one.npo)
}

#' Get the data frame generated by a table build function. 
#'
#' Helper function that extracts a single table (the table associated with the function name passed as an argument) from a list of multiple tables from multiple nonprofits. It is used by build_tables() to write a batch of the data to file. 
#'
#' @param fx.name A function name from get_fx_names().
#' @param all.npos A list of parsed NPO data.
#' @param time A string representing the timestamp for the file.
#' @param year An integer specifying the tax year.
#'
#' @return None. Writes data to a CSV file.
#' @examples
#' # extract all tables for ten 990 filers
#' fx.names <- get_fx_names()
#' timestamp <- format(Sys.time(), "%b-%d-%Y-%Hh-%Mm")
#' # sample of 10 orgs in 2020
#' i2 <- dplyr::filter( 
#'       tinyindex, 
#'       TaxYear == 2020,
#'       FormType %in% c("990","990EZ") )
#' urls <- i2$URL[1:10]  
#' # pool data for the given table from npos in the sample
#' all.npos <- purrr::map( urls, parse_npo, fx.names )
#' get_fxdf( "BUILD_F9_P01_T00_SUMMARY", all.npos, timestamp, 2020 )
#' # CREATES FILE: "2020-F9-P01-T00-SUMMARY-Jan-22-2025-15h-13m.csv"
#' @export
get_fxdf <- function(fx.name, all.npos, time, year) {
  t.name <- substr(fx.name, start = 7, stop = nchar(fx.name))
  t.name <- gsub("_", "-", t.name)
  df.list <- lapply(all.npos, '[[', fx.name)
  df <- dplyr::bind_rows(df.list)
  if( nrow(df) > 0 )
  { data.table::fwrite(df, file = paste0(year, "-", t.name, "-", time, ".csv")) }
}

#' Get Function Names
#'
#' Retrieves a list of function names based on table names and exclusion criteria.
#'
#' @param table.names An optional vector of table names. Defaults to all tables in the concordance.
#' @param exclude A vector of substrings to exclude from table names.
#'
#' @return A vector of function names.
#' @examples
#' fx_names <- get_fx_names(table.names = c("TABLE1", "TABLE2"))
#' @export
get_fx_names <- function(table.names = NULL, exclude = c("T99")) {
  if( ! exists("concordance") ){ concordance <- get_concordance() }
  if (is.null(table.names)) { table.names <- concordance[["rdb_table"]] |> unique() }
  if (!is.null(exclude)) {
    exclude <- paste0("-", exclude, "-", collapse = "|")
    table.names <- table.names[!grepl(exclude, table.names)]
  }
  table.names <- table.names[ table.names != "" ]
  fx.names <- gsub("-", "_", table.names)
  fx.names <- paste0("BUILD_", fx.names)
  return(fx.names)
}

#' Build Tables
#'
#' Extracts and writes table data from URLs.
#'
#' @param urls A vector of URLs to process.
#' @param year The tax year associated with the data.
#' @param fx.names A vector of function names for processing tables.
#' @param table.names Optional vector of table names. Defaults to NULL.
#'
#' @return A vector of failed URLs.
#' @examples
#' failed_urls <- build_tables(urls, year = 2023)
#' @export
build_tables <- function(urls, year, fx.names = NULL, table.names = NULL) {
  if( ! exists("concordance") ){ concordance <- get_concordance() }
  if (is.null(table.names)) { table.names <- concordance[["rdb_table"]] |> unique() }
  if (is.null(fx.names)) { fx.names <- get_fx_names(table.names, exclude = "T99") }
  fx.names <- c(fx.names, "BUILD_SCHEDULE_TABLE")
  # TABLE.HEADERS <- get_table_headers()
  all.npos <- purrr::map( urls, parse_npo, fx.names )
  time <- format(Sys.time(), "%b-%d-%Y-%Hh-%Mm")
  rand <- paste(sample(LETTERS, 5), collapse = "")
  time <- paste0("time-", time, "-", rand)
  purrr::walk(fx.names, get_fxdf, all.npos, time, year)
  failed.urls <- lapply(all.npos, '[[', "FAIL") |> unlist()
  print(paste("There are", length(failed.urls), "failed XML URLs to re-try."))
  return(failed.urls)
}


#' @title Passing arguments to parSapply
#' @description Pass arguments to parallel sapply table function.  
#' @details Helper function to send variables to the build_tables function in parSapply framework. 
#' @export
parsapply_tables <- function( index.group ){
  require( irs990efiler ) 
  # 'fx.names' and 'year' passed through clusterExport
  failed.urls <- build_tables( index.group, fx.names=fx.names, year=year ) 
  return( failed.urls )
}


#' Parallel Build of Tables
#'
#' Builds tables in parallel using multiple cores.
#'
#' @param groups A list of URL groups to process.
#' @param year The tax year associated with the data.
#' @param fx.names A vector of function names for processing tables.
#'
#' @return A vector of failed URLs.
#' @examples
#' failed_urls <- build_tables_parallel(groups, year = 2023)
#' @export
build_tables_parallel <- function(groups, year, fx.names = NULL) {
  if (is.null(fx.names)) {fx.names <- get_fx_names(exclude = "T99")}
  num.cores <- parallel::detectCores() - 1
  cl <- parallel::makeCluster(num.cores)
  parallel::clusterExport(cl, varlist = c("year", "fx.names"), envir = environment())
  results <- parallel::parSapply(cl, X = groups, FUN = parsapply_tables)
  parallel::stopCluster(cl)
  failed.urls <- unlist(results)
  return(failed.urls)
}